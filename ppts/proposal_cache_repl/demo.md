title: Cache Replacement Project
speaker: Jipeng Wu
url:
transition: vertical3d
files: /js/demo.js,/css/demo.css,/js/zoom.js
theme: dark
usemathjax: no

[slide]
# A Frequent-Pattern-Aware Harware Prefecher
## Jipeng Wu

[slide]
## Background: Why Prefetching?  
----
![system-dram](/img/system-dram.png)
* SRAM can keep pace with processor memory request rates. {:&.zoomIn}
* LLC miss latency is a significent bottleneck.
* A program working on a large array.{:&.zoomIn}
  * Caching policies are defeated by such programs with low locality.
* A data block in that array is constantly referenced and updated.
  * Such capacity miss can be avoided by fectching before referenced(in parallel with processor computation).



[slide]
## Existing prefechers
----
* Access Map Pattern Matching(AMPM):
  * per cache line structure(untouched, demand accessed, prefetched);
  * AMPM only detects strides.  {:&.zoomIn}
* Spatial Memory Streaming(SMS):
  * AGT(Active Generation Table): AGT entries are spatial pattern bitmaps.
  * PHT(Pattern History Table): when a AGT entry evicted, it's placed in PHT.
  * The PC+offset of the load instruction are used to look up the PHT. If there is a match, data blocks indicated by PHT entry's bitmap will be prefeched.
* Variable-Length Delta Prefecher(VLDP):
  * VLDP captures variable-length delta patterns rather than fixed-length strides.
  * Standalone buffers: Per-page Delta History Buffer, Delta Prediction Tables, Offset Prediction Tables.

[slide]
## FPA Goal
----
* Detecting more general data patterns.
* Using limited LLC storage budget only and no standalone hardware buffers.
* Choose a proper tradeoff between coverage/traning time/complexity and accuracy based on simulation results.

[slide]
## How to track history
----
* The Global History Buffer:  {:&.zoomIn}
  * The GHB is a circular buffer, and each cache miss adds a new entry to the buffer.
  * The index table points to the most recent occurrence of PC in global history.
  * Therefore GHB can be looked up by PC. But the history length is 1 and this method replies on PC.
* AMMP's Per cache line based history:
  * Each cache line assigned with 2 bits to indicate its state: untouched, demand accessed, prefetched.
  * It's not really a history buffer. It requires a walkthrough of adjacent cache lines
* VLDP's Page-based design:
  * DHB Entry: (i) page number(ii) page offset of the last address accessed in this page, (iii) sequence of up to 4 recently observed deltas, (iv) the DPT level used for the latest delta prediction, (v) the number of times this page has been used, and (vi) 4 recently prefetched offsets.
  * Global DPT+OPT stores prediction and accuracy information.


[slide]
## Delta patterns
----
Since a data access pattern can repeat across different regions of memory, it
* Address Sequence S1: {A, A+1,A+4,A+3,A-2}

  Address Sequence S2: {B, B-1,B+3,B+1,B-1,B+5}

  Address Sequence S3: {C, C+1,C+4,C+3,C-2}

* {S1,S2,S3} -> {{0,1,4,3,-2}, {0,-1,3,1,-1,5}}

[slide]
## Frequent Pattern Capture
----
![fp-growth](/img/fp-growth.png)


[slide]
## Simulation Environment
----
* Simulator: CMPSIM {:&.zoomIn}
* 3 layer cache model + out-of-order 8-stage pipeline
* Non-inclusive virtual address LLC: 16K cache lines
* Cache line size: 64B
* Reserved bits per cache line: 8 bits
* Storage budget: 16K*8+1K=129K

[slide]
## Workload and Performance Evaluation
----
* Single-threaded workload generated by pin tool
* Comparing FPA with AMPM(Access Map Pattern Matching) and SMS(Spatial Memory Streaming).
